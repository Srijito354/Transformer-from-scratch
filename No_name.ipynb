{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_gen(sentence):\n",
    "    global words\n",
    "    words = sentence.lower().split(' ')\n",
    "    word_idx = {elem: idx for idx, elem in enumerate(set(words))}\n",
    "    idx_only = [idx for idx, _ in enumerate(set(words))]\n",
    "    global elem_only\n",
    "    global vocab_size\n",
    "    vocab_size = len(word_idx)\n",
    "    embedding_dim = 16\n",
    "    embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "    input_tensor = torch.LongTensor(idx_only)\n",
    "    embedding_tensor = embedding_layer(input_tensor)\n",
    "    return embedding_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat = embedding_gen(\"If you miss the train I am on you will know I am gone You will hear a whistle blow a hundred miles\")\n",
    "softmax = nn.Softmax()\n",
    "embedding_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6458,  2.6735, -0.6294, -0.9352, -1.7030,  0.6741,  0.8172, -0.4604,\n",
       "         -0.9493, -1.8822, -1.0437,  0.1781,  0.8973, -0.0976, -0.3789,  1.4148],\n",
       "        [ 0.8589, -1.5207, -0.5662, -0.2485, -0.4772, -0.1564,  0.6059,  1.0436,\n",
       "          1.2279,  0.8374, -0.0343, -0.0742,  1.5189, -0.7008,  1.1504, -0.1686],\n",
       "        [-0.0294,  1.1959,  1.0094, -0.6198,  0.7178, -0.6988,  1.5429, -1.4265,\n",
       "         -0.5134, -0.6972,  1.0297, -0.8999,  1.7934, -0.6760, -0.7946, -0.3960],\n",
       "        [-0.7651,  0.2402, -0.7144,  0.3178,  0.9697,  1.3702, -0.8142, -0.3472,\n",
       "         -0.3337, -0.2528, -0.2846, -0.2778, -1.9415,  0.0288, -0.5864, -0.0477],\n",
       "        [ 0.9641, -1.2722, -0.6363, -0.3000,  0.8644, -2.0459, -0.1021, -0.9000,\n",
       "          1.1702,  1.6939,  0.1856,  0.0214, -0.4317,  0.7765, -1.3990,  0.3690],\n",
       "        [-0.8177,  0.6763,  0.8899,  1.3792, -2.7850,  0.3200,  0.2640,  0.7285,\n",
       "          0.0619, -0.4340, -0.1591, -0.0916,  2.5104,  1.1186, -1.0749, -2.5823],\n",
       "        [ 1.0671,  0.5567,  0.3005,  1.4181, -0.3886,  0.7820, -0.1668,  0.4718,\n",
       "         -1.6321, -0.8670,  0.9107, -1.4251,  1.8429, -0.8445,  0.8338,  0.3558],\n",
       "        [ 1.0998,  0.6498, -0.3242,  0.1741,  1.0099, -1.7934, -0.0137, -0.6133,\n",
       "         -0.2064, -1.3614,  0.0231, -0.9189, -0.8157, -0.1583,  1.0098,  0.8710],\n",
       "        [ 1.4083, -1.7355, -0.5961, -0.1068,  0.5776, -0.5775,  0.4932,  1.3047,\n",
       "         -0.5385, -0.6862, -0.1651, -0.6678,  0.0297, -0.6749,  0.6655, -0.4303],\n",
       "        [ 0.3463,  1.1320, -0.3621, -0.5385, -1.2585,  0.3282, -0.0511,  1.4727,\n",
       "          0.4857, -1.4182, -0.7618, -0.7145, -3.0435, -0.1356, -0.1185,  1.7824],\n",
       "        [ 1.3273, -2.7989, -1.3120, -0.2850, -0.2006, -0.3671, -0.4396, -0.2631,\n",
       "          0.3105,  3.3853, -1.8438, -0.1116,  0.3329,  0.3287, -1.4064,  0.5840],\n",
       "        [-0.5704,  1.5494, -1.0058,  1.7138,  0.3989,  1.2876, -0.5880, -0.1445,\n",
       "         -1.5804,  1.8386,  0.1898, -0.7192, -1.9584, -0.8428, -0.1678, -0.9384],\n",
       "        [ 0.6941, -0.1661,  1.2042,  0.8031, -0.9498,  0.6787,  0.2084,  0.6853,\n",
       "          0.4758, -0.1162, -1.0064, -0.4631,  0.4907, -1.2832, -0.8289, -0.6377],\n",
       "        [-1.9895, -0.9866, -1.2695,  0.0239, -1.6507, -0.8788, -0.5826,  1.2431,\n",
       "          0.8293, -1.0077,  0.6349, -0.4127,  1.6754,  0.7118, -0.1333, -0.2167],\n",
       "        [-0.8930, -0.2745, -1.1684,  0.0916, -0.4787, -0.2193,  0.1652,  1.2230,\n",
       "         -0.6191, -1.4214, -0.1741, -0.3294, -0.5281,  0.3692,  0.7256, -0.4394],\n",
       "        [-1.9046,  1.3688, -2.3986,  0.0266,  0.3787,  0.6360,  0.7283,  0.0611,\n",
       "          0.1718,  0.1184, -0.6106,  0.1621, -0.2179, -1.1093,  0.4259, -1.0547],\n",
       "        [-1.0193, -0.1678,  0.1045,  0.2203, -1.3299,  0.4428,  1.7158,  0.9623,\n",
       "         -2.0765, -0.5353, -0.6152, -0.1848, -0.9955, -0.3947, -0.7369, -1.2102]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = torch.zeros(embedding_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0247, 0.2138, 0.0410, 0.0352, 0.0240, 0.0787, 0.0845, 0.0446, 0.0349,\n",
       "         0.0219, 0.0333, 0.0614, 0.0880, 0.0535, 0.0465, 0.1140],\n",
       "        [0.0798, 0.0243, 0.0392, 0.0459, 0.0409, 0.0481, 0.0704, 0.0876, 0.0960,\n",
       "         0.0790, 0.0511, 0.0501, 0.1111, 0.0366, 0.0924, 0.0478],\n",
       "        [0.0535, 0.0987, 0.0899, 0.0398, 0.0777, 0.0383, 0.1174, 0.0266, 0.0420,\n",
       "         0.0383, 0.0908, 0.0346, 0.1330, 0.0387, 0.0365, 0.0445],\n",
       "        [0.0444, 0.0733, 0.0455, 0.0762, 0.1056, 0.1290, 0.0433, 0.0547, 0.0550,\n",
       "         0.0573, 0.0564, 0.0566, 0.0246, 0.0660, 0.0485, 0.0635],\n",
       "        [0.0929, 0.0304, 0.0417, 0.0494, 0.0883, 0.0206, 0.0545, 0.0366, 0.1029,\n",
       "         0.1337, 0.0629, 0.0580, 0.0462, 0.0845, 0.0285, 0.0690],\n",
       "        [0.0342, 0.0721, 0.0802, 0.1024, 0.0128, 0.0603, 0.0587, 0.0740, 0.0530,\n",
       "         0.0414, 0.0475, 0.0491, 0.1803, 0.0899, 0.0300, 0.0141],\n",
       "        [0.0863, 0.0669, 0.0589, 0.1029, 0.0417, 0.0749, 0.0466, 0.0641, 0.0224,\n",
       "         0.0328, 0.0799, 0.0248, 0.1273, 0.0332, 0.0768, 0.0605],\n",
       "        [0.1038, 0.0829, 0.0509, 0.0653, 0.0992, 0.0244, 0.0595, 0.0441, 0.0540,\n",
       "         0.0303, 0.0606, 0.0378, 0.0398, 0.0553, 0.0992, 0.0926],\n",
       "        [0.1229, 0.0255, 0.0451, 0.0576, 0.0811, 0.0455, 0.0778, 0.1167, 0.0464,\n",
       "         0.0431, 0.0560, 0.0435, 0.0617, 0.0434, 0.0848, 0.0490],\n",
       "        [0.0699, 0.1036, 0.0491, 0.0449, 0.0313, 0.0693, 0.0573, 0.1228, 0.0750,\n",
       "         0.0289, 0.0402, 0.0411, 0.0128, 0.0549, 0.0554, 0.1434],\n",
       "        [0.1015, 0.0129, 0.0271, 0.0453, 0.0473, 0.0435, 0.0420, 0.0458, 0.0611,\n",
       "         0.2841, 0.0208, 0.0494, 0.0617, 0.0616, 0.0259, 0.0700],\n",
       "        [0.0417, 0.1204, 0.0336, 0.1307, 0.0677, 0.1057, 0.0414, 0.0516, 0.0252,\n",
       "         0.1392, 0.0610, 0.0387, 0.0208, 0.0364, 0.0510, 0.0347],\n",
       "        [0.0832, 0.0541, 0.1074, 0.0879, 0.0366, 0.0826, 0.0653, 0.0829, 0.0746,\n",
       "         0.0555, 0.0356, 0.0467, 0.0752, 0.0310, 0.0389, 0.0428],\n",
       "        [0.0230, 0.0379, 0.0329, 0.0629, 0.0272, 0.0400, 0.0464, 0.1157, 0.0941,\n",
       "         0.0375, 0.0854, 0.0506, 0.1436, 0.0887, 0.0581, 0.0558],\n",
       "        [0.0429, 0.0584, 0.0373, 0.0701, 0.0527, 0.0600, 0.0728, 0.1235, 0.0491,\n",
       "         0.0329, 0.0614, 0.0568, 0.0514, 0.0806, 0.0963, 0.0538],\n",
       "        [0.0241, 0.1239, 0.0188, 0.0633, 0.0755, 0.0859, 0.0899, 0.0644, 0.0681,\n",
       "         0.0663, 0.0460, 0.0677, 0.0560, 0.0359, 0.0773, 0.0369],\n",
       "        [0.0404, 0.0619, 0.0709, 0.0751, 0.0346, 0.0840, 0.1587, 0.1089, 0.0238,\n",
       "         0.0515, 0.0495, 0.0613, 0.0409, 0.0552, 0.0466, 0.0367]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum1 = empty+embedding_mat\n",
    "softmax(sum1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def generate_positional_encoding(sequence_length, embedding_dim):\n",
    "    pe = torch.zeros(sequence_length, embedding_dim)\n",
    "    position = torch.arange(0, sequence_length, dtype=torch.float).unsqueeze(1)\n",
    "    div_term = torch.exp(\n",
    "        torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.0) / embedding_dim)\n",
    "    )\n",
    "\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)  # even indices\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)  # odd indices\n",
    "\n",
    "    return pe\n",
    "\n",
    "pos_encoding = generate_positional_encoding(sequence_length=vocab_size, embedding_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6458e+00,  3.6735e+00, -6.2937e-01,  6.4818e-02, -1.7030e+00,\n",
       "          1.6741e+00,  8.1716e-01,  5.3956e-01, -9.4928e-01, -8.8221e-01,\n",
       "         -1.0437e+00,  1.1781e+00,  8.9727e-01,  9.0235e-01, -3.7890e-01,\n",
       "          2.4148e+00],\n",
       "        [ 1.7004e+00, -9.8039e-01, -2.5521e-01,  7.0189e-01, -3.7741e-01,\n",
       "          8.3863e-01,  6.3754e-01,  2.0431e+00,  1.2379e+00,  1.8374e+00,\n",
       "         -3.1149e-02,  9.2584e-01,  1.5199e+00,  2.9920e-01,  1.1507e+00,\n",
       "          8.3137e-01],\n",
       "        [ 8.7995e-01,  7.7972e-01,  1.6005e+00,  1.8683e-01,  9.1651e-01,\n",
       "          2.8128e-01,  1.6061e+00, -4.2849e-01, -4.9344e-01,  3.0260e-01,\n",
       "          1.0361e+00,  1.0008e-01,  1.7954e+00,  3.2395e-01, -7.9396e-01,\n",
       "          6.0405e-01],\n",
       "        [-6.2395e-01, -7.4976e-01,  9.8280e-02,  9.0058e-01,  1.2652e+00,\n",
       "          2.3256e+00, -7.1945e-01,  6.4834e-01, -3.0373e-01,  7.4678e-01,\n",
       "         -2.7510e-01,  7.2214e-01, -1.9385e+00,  1.0288e+00, -5.8541e-01,\n",
       "          9.5228e-01],\n",
       "        [ 2.0725e-01, -1.9258e+00,  3.1730e-01,  1.1311e-03,  1.2538e+00,\n",
       "         -1.1248e+00,  2.4044e-02,  9.2015e-02,  1.2102e+00,  2.6931e+00,\n",
       "          1.9828e-01,  1.0213e+00, -4.2767e-01,  1.7765e+00, -1.3977e+00,\n",
       "          1.3690e+00],\n",
       "        [-1.7766e+00,  9.6001e-01,  1.8899e+00,  1.3688e+00, -2.3055e+00,\n",
       "          1.1976e+00,  4.2148e-01,  1.7160e+00,  1.1185e-01,  5.6477e-01,\n",
       "         -1.4331e-01,  9.0825e-01,  2.5154e+00,  2.1186e+00, -1.0733e+00,\n",
       "         -1.5823e+00],\n",
       "        [ 7.8772e-01,  1.5169e+00,  1.2476e+00,  1.0973e+00,  1.7602e-01,\n",
       "          1.6073e+00,  2.1809e-02,  1.4538e+00, -1.5722e+00,  1.3122e-01,\n",
       "          9.2972e-01, -4.2524e-01,  1.8489e+00,  1.5552e-01,  8.3569e-01,\n",
       "          1.3558e+00],\n",
       "        [ 1.7568e+00,  1.4037e+00,  4.7622e-01, -4.2538e-01,  1.6542e+00,\n",
       "         -1.0286e+00,  2.0586e-01,  3.6229e-01, -1.3642e-01, -3.6383e-01,\n",
       "          4.5236e-02,  8.0848e-02, -8.0873e-01,  8.4171e-01,  1.0120e+00,\n",
       "          1.8710e+00],\n",
       "        [ 2.3977e+00, -1.8810e+00, -2.1776e-02, -9.2545e-01,  1.2949e+00,\n",
       "          1.1918e-01,  7.4348e-01,  2.2729e+00, -4.5860e-01,  3.1060e-01,\n",
       "         -1.3976e-01,  3.3191e-01,  3.7673e-02,  3.2509e-01,  6.6807e-01,\n",
       "          5.6972e-01],\n",
       "        [ 7.5843e-01,  2.2083e-01, -7.0872e-02, -1.4951e+00, -4.7513e-01,\n",
       "          9.4984e-01,  2.2973e-01,  2.4324e+00,  5.7560e-01, -4.2228e-01,\n",
       "         -7.3332e-01,  2.8505e-01, -3.0345e+00,  8.6441e-01, -1.1569e-01,\n",
       "          2.7824e+00],\n",
       "        [ 7.8331e-01, -3.6380e+00, -1.3327e+00, -1.2848e+00,  6.4083e-01,\n",
       "          1.7320e-01, -1.2865e-01,  6.8731e-01,  4.1034e-01,  4.3803e+00,\n",
       "         -1.8122e+00,  8.8792e-01,  3.4294e-01,  1.3287e+00, -1.4033e+00,\n",
       "          1.5840e+00],\n",
       "        [-1.5704e+00,  1.5539e+00, -1.3363e+00,  7.7001e-01,  1.2901e+00,\n",
       "          1.7412e+00, -2.4715e-01,  7.9560e-01, -1.4706e+00,  2.8326e+00,\n",
       "          2.2460e-01,  2.8019e-01, -1.9474e+00,  1.5716e-01, -1.6429e-01,\n",
       "          6.1579e-02],\n",
       "        [ 1.5755e-01,  6.7773e-01,  5.9654e-01,  8.9501e-03, -1.7777e-02,\n",
       "          1.0410e+00,  5.7882e-01,  1.6142e+00,  5.9553e-01,  8.7664e-01,\n",
       "         -9.6845e-01,  5.3618e-01,  5.0269e-01, -2.8331e-01, -8.2508e-01,\n",
       "          3.6231e-01],\n",
       "        [-1.5693e+00, -7.9192e-02, -2.0940e+00, -5.4195e-01, -6.8712e-01,\n",
       "         -6.1129e-01, -1.8296e-01,  2.1597e+00,  9.5890e-01, -1.6167e-02,\n",
       "          6.7598e-01,  5.8645e-01,  1.6884e+00,  1.7117e+00, -1.2922e-01,\n",
       "          7.8334e-01],\n",
       "        [ 9.7608e-02, -1.3780e-01, -2.1280e+00, -1.8974e-01,  5.0678e-01,\n",
       "         -4.9336e-02,  5.9362e-01,  2.1266e+00, -4.7959e-01, -4.3118e-01,\n",
       "         -1.2986e-01,  6.6960e-01, -5.1407e-01,  1.3691e+00,  7.2999e-01,\n",
       "          5.6063e-01],\n",
       "        [-1.2543e+00,  6.0906e-01, -3.3981e+00,  5.7643e-02,  1.3762e+00,\n",
       "          7.0676e-01,  1.1851e+00,  9.5068e-01,  3.2120e-01,  1.1071e+00,\n",
       "         -5.6318e-01,  1.1610e+00, -2.0292e-01, -1.0940e-01,  4.3061e-01,\n",
       "         -5.4707e-02],\n",
       "        [-1.3072e+00, -1.1255e+00, -8.3579e-01,  5.6065e-01, -3.3036e-01,\n",
       "          4.1360e-01,  2.2004e+00,  1.8371e+00, -1.9172e+00,  4.5197e-01,\n",
       "         -5.6458e-01,  8.1388e-01, -9.7950e-01,  6.0516e-01, -7.3181e-01,\n",
       "         -2.1019e-01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finna = embedding_mat + pos_encoding\n",
    "finna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, K, V = finna, finna, finna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1628e-01,  1.5031e-02, -5.4273e-01,  1.1209e-01, -6.9620e-01,\n",
       "          3.5219e-01, -4.7813e-01,  1.1999e+00,  2.3619e-01,  5.1547e-01,\n",
       "          1.1057e+00,  1.5331e-01, -1.3334e-01, -1.6258e-01, -6.7510e-02,\n",
       "          3.4149e-01],\n",
       "        [ 3.8895e-01, -2.4875e-01, -6.5384e-01, -4.2624e-01, -2.2442e-01,\n",
       "         -1.5791e-01, -2.5660e-01,  6.1157e-01,  2.0768e-01,  2.5707e-01,\n",
       "          6.9736e-01, -3.6542e-01, -2.1826e-01, -1.1950e-02, -1.2797e-01,\n",
       "         -2.5035e-01],\n",
       "        [ 5.8866e-01, -1.3555e-01, -4.7411e-01, -1.3321e-01, -5.8339e-02,\n",
       "         -2.0503e-01,  3.8973e-02,  6.7007e-01,  1.8345e-01,  2.8732e-01,\n",
       "          4.9910e-01, -3.8971e-01, -9.7846e-02,  1.4826e-02,  1.3171e-01,\n",
       "         -2.5578e-01],\n",
       "        [-4.5744e-04, -2.6747e-01, -7.2635e-01, -3.3391e-01, -5.5680e-01,\n",
       "          1.2621e-01, -3.9390e-01,  7.3259e-01,  1.3276e-01,  3.7888e-01,\n",
       "          9.7755e-01, -1.0840e-01, -2.0771e-01, -3.3677e-02, -2.2171e-01,\n",
       "          1.4919e-02],\n",
       "        [ 2.3719e-01, -3.0723e-01, -7.5812e-01, -5.0308e-01, -3.7736e-01,\n",
       "         -3.1188e-03, -2.8841e-01,  5.9681e-01,  1.3170e-01,  2.8551e-01,\n",
       "          9.6959e-01, -1.6875e-01, -3.5656e-01,  3.7477e-02, -2.3249e-01,\n",
       "         -2.3902e-01],\n",
       "        [ 5.4312e-01, -2.2630e-01, -5.2611e-01, -2.5240e-01, -1.8454e-02,\n",
       "         -2.9564e-01, -6.7153e-03,  5.3544e-01,  1.3835e-01,  2.4258e-01,\n",
       "          4.8564e-01, -4.4091e-01, -3.2035e-02,  6.8722e-02,  4.2171e-02,\n",
       "         -2.9526e-01],\n",
       "        [ 4.5627e-01, -1.3128e-01, -5.0250e-01, -1.4813e-01, -1.4757e-01,\n",
       "         -1.9539e-01, -1.0155e-01,  6.8845e-01,  2.2822e-01,  3.2386e-01,\n",
       "          5.2032e-01, -3.9008e-01, -7.6621e-02, -3.2284e-02,  6.7836e-02,\n",
       "         -1.4257e-01],\n",
       "        [ 2.5847e-01, -2.0891e-01, -6.1071e-01, -2.5232e-01, -3.4080e-01,\n",
       "         -3.4104e-02, -2.3617e-01,  7.0064e-01,  1.7997e-01,  3.5060e-01,\n",
       "          7.5202e-01, -2.7582e-01, -1.6587e-01, -3.1442e-02, -5.3881e-02,\n",
       "         -1.0076e-01],\n",
       "        [ 3.3769e-01, -1.6612e-01, -5.8629e-01, -2.5382e-01, -3.5289e-01,\n",
       "         -1.8473e-02, -2.6183e-01,  7.1852e-01,  2.0710e-01,  3.8904e-01,\n",
       "          7.0706e-01, -2.7734e-01, -2.2985e-01, -7.9444e-02, -2.9790e-02,\n",
       "         -7.0994e-02],\n",
       "        [-3.8422e-02, -2.3486e-01, -6.8971e-01, -3.1308e-01, -5.5084e-01,\n",
       "          9.9324e-02, -4.7520e-01,  7.3576e-01,  1.2209e-01,  4.6653e-01,\n",
       "          9.1026e-01, -1.7310e-01, -2.3102e-01, -1.3420e-01, -2.3322e-01,\n",
       "          8.5032e-02],\n",
       "        [ 9.8110e-02, -2.0952e-01, -7.4164e-01, -3.7829e-01, -5.7671e-01,\n",
       "          1.9573e-01, -3.8836e-01,  7.8550e-01,  1.7006e-01,  3.7681e-01,\n",
       "          1.0941e+00,  8.1846e-03, -3.8963e-01, -3.2183e-02, -2.1338e-01,\n",
       "         -4.7120e-02],\n",
       "        [-1.0936e-01, -3.7423e-01, -8.0281e-01, -4.0295e-01, -5.2827e-01,\n",
       "          6.0494e-02, -3.7610e-01,  6.2861e-01,  8.0127e-02,  3.2141e-01,\n",
       "          1.0136e+00, -1.4136e-01, -1.1234e-01,  3.8646e-02, -3.0254e-01,\n",
       "         -3.5495e-02],\n",
       "        [ 2.9098e-01, -2.6017e-01, -6.2921e-01, -3.2606e-01, -2.5666e-01,\n",
       "         -1.3677e-01, -2.1756e-01,  5.9928e-01,  1.4916e-01,  3.0571e-01,\n",
       "          6.8425e-01, -3.5352e-01, -1.2218e-01, -1.1276e-03, -9.5153e-02,\n",
       "         -1.7068e-01],\n",
       "        [-9.7115e-02, -7.0905e-02, -5.7822e-01, -3.3574e-02, -6.2891e-01,\n",
       "          2.6756e-01, -4.4768e-01,  9.9806e-01,  1.4990e-01,  5.2380e-01,\n",
       "          1.0262e+00,  5.0736e-02, -1.9039e-01, -1.3442e-01, -9.4380e-02,\n",
       "          2.3106e-01],\n",
       "        [-9.7130e-02, -1.2618e-01, -6.3334e-01, -1.2161e-01, -6.4968e-01,\n",
       "          2.6158e-01, -4.5551e-01,  9.5230e-01,  1.6768e-01,  4.8577e-01,\n",
       "          1.0374e+00,  2.0329e-02, -2.0605e-01, -1.2070e-01, -1.4006e-01,\n",
       "          1.9406e-01],\n",
       "        [-3.0384e-01, -1.4892e-01, -6.8821e-01, -8.8329e-02, -7.7585e-01,\n",
       "          3.9523e-01, -4.8627e-01,  1.0487e+00,  1.4414e-01,  4.6084e-01,\n",
       "          1.2333e+00,  1.8094e-01, -1.6094e-01, -7.5210e-02, -2.0498e-01,\n",
       "          2.5460e-01],\n",
       "        [ 6.5484e-02, -2.6164e-01, -6.8466e-01, -3.0828e-01, -4.6036e-01,\n",
       "          3.8671e-02, -3.4602e-01,  6.7583e-01,  1.1114e-01,  4.0029e-01,\n",
       "          8.7520e-01, -1.8954e-01, -1.7698e-01, -4.4541e-02, -1.7589e-01,\n",
       "         -1.1477e-02]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "w_q = nn.Linear(in_features=16, out_features=16)\n",
    "w_k = nn.Linear(in_features=16, out_features=16)\n",
    "w_v = nn.Linear(in_features=16, out_features=16)\n",
    "\n",
    "Q = w_q(Q)\n",
    "K = w_k(K)\n",
    "V = w_k(V)\n",
    "\n",
    "q_k = torch.matmul(Q, K.transpose(-2, -1))\n",
    "embedding_dim = 16\n",
    "q_k = q_k/math.sqrt(embedding_dim)\n",
    "q_k = softmax(q_k)\n",
    "\n",
    "q_k_v = torch.matmul(q_k, V)\n",
    "q_k_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4402,  2.0681, -1.0041, -0.1514, -1.7796,  1.0175, -0.0490,  0.8361,\n",
       "         -0.7140, -0.4950, -0.2241,  0.5783,  0.2196,  0.2043, -0.5454,  1.4788],\n",
       "        [ 1.3335, -1.8662, -1.5575, -0.4152, -1.2613, -0.0247, -0.3137,  1.8787,\n",
       "          0.7129,  1.3385, -0.0386, -0.1406,  0.5741, -0.4040,  0.3051, -0.1208],\n",
       "        [ 1.2256,  0.0819,  0.7510, -0.7373,  0.3788, -0.7059,  1.4705, -0.4766,\n",
       "         -1.2417,  0.0067,  1.3180, -1.2135,  1.5432, -0.3417, -1.7304, -0.3286],\n",
       "        [-0.7160, -1.0624, -0.7193,  0.3340,  0.4590,  1.9960, -1.1471,  1.0519,\n",
       "         -0.3163,  0.8268,  0.4537,  0.3755, -2.0577,  0.7117, -0.8771,  0.6871],\n",
       "        [ 0.1331, -1.9035, -0.5403, -0.5868,  0.4616, -1.0629, -0.4061,  0.3189,\n",
       "          0.8157,  2.0605,  0.6833,  0.4435, -0.8015,  1.1747, -1.4449,  0.6545],\n",
       "        [-1.2081,  0.2220,  0.6800,  0.5002, -2.0009,  0.3443, -0.0099,  1.3253,\n",
       "         -0.1295,  0.2755, -0.0625,  0.0283,  1.4939,  1.2787, -1.0610, -1.6763],\n",
       "        [ 0.5692,  0.7242,  0.0231,  0.2465, -0.7615,  0.7530, -0.8799,  1.5526,\n",
       "         -2.2639, -0.2945,  0.7947, -1.6852,  1.1475, -0.6577,  0.1965,  0.5355],\n",
       "        [ 1.7371,  0.8381, -0.6183, -1.2135,  0.9680, -1.6353, -0.5042,  0.6936,\n",
       "         -0.4233, -0.4855,  0.4025, -0.6846, -1.5388,  0.4168,  0.5788,  1.4685],\n",
       "        [ 1.9800, -1.9978, -0.8009, -1.2760,  0.4884, -0.2114,  0.1055,  2.1929,\n",
       "         -0.5043,  0.2868,  0.1767, -0.2497, -0.4550, -0.0908,  0.2358,  0.1197],\n",
       "        [ 0.3904, -0.0962, -0.5910, -1.2854, -0.7669,  0.6086, -0.2496,  2.0131,\n",
       "          0.3756, -0.0575,  0.0304, -0.0127, -2.2514,  0.3971, -0.3182,  1.8138],\n",
       "        [ 0.4251, -2.1014, -1.1540, -0.9343, -0.0115,  0.1513, -0.3220,  0.7411,\n",
       "          0.2643,  2.4958, -0.4295,  0.4330, -0.0707,  0.6469, -0.9095,  0.7753],\n",
       "        [-1.2560,  0.7390, -1.5766,  0.1720,  0.4474,  1.1729, -0.5189,  0.9096,\n",
       "         -1.0543,  2.1165,  0.7798,  0.0128, -1.5212,  0.0525, -0.4098, -0.0659],\n",
       "        [ 0.1992,  0.1555, -0.4785, -0.8791, -0.8190,  0.8410,  0.0762,  2.6848,\n",
       "          0.6162,  1.2326, -0.8328, -0.1753,  0.1034, -0.8331, -1.7285, -0.1626],\n",
       "        [-1.3329, -0.2652, -2.0411, -0.5648, -1.0862, -0.4016, -0.6036,  2.0640,\n",
       "          0.6212,  0.1979,  1.0390,  0.2891,  0.8952,  0.9511, -0.3170,  0.5547],\n",
       "        [-0.1716, -0.4018, -2.5752, -0.4430, -0.2964,  0.0127, -0.0519,  2.5075,\n",
       "         -0.4435, -0.1246,  0.6177,  0.4284, -0.7988,  0.9144,  0.3413,  0.4847],\n",
       "        [-1.2803,  0.1943, -3.1272, -0.1643,  0.2967,  0.6632,  0.3686,  1.3188,\n",
       "          0.1980,  1.0036,  0.3477,  0.8385, -0.4077, -0.2768,  0.0229,  0.0041],\n",
       "        [-0.9463, -1.0668, -1.1774,  0.2929, -0.5722,  0.4587,  1.6215,  2.1676,\n",
       "         -1.4143,  0.7904,  0.3412,  0.6014, -0.8756,  0.5485, -0.6692, -0.1003]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm_layer1 = q_k_v+finna\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "add_norm_layer1 = layer_norm(add_norm_layer1)\n",
    "add_norm_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7456e+00,  1.7239e+00, -1.0277e+00, -1.7014e-01, -2.0429e+00,\n",
       "          9.4221e-01,  5.3342e-02,  9.8642e-01, -4.7672e-01, -2.5143e-01,\n",
       "         -1.0077e-01,  5.7825e-01,  3.7561e-01,  1.5872e-01, -3.8500e-01,\n",
       "          1.3818e+00],\n",
       "        [ 1.3473e+00, -1.8149e+00, -1.5083e+00, -5.0057e-01, -1.0945e+00,\n",
       "          7.4877e-02, -4.8614e-01,  1.8071e+00,  8.8673e-01,  1.6249e+00,\n",
       "         -1.5034e-01, -1.5522e-01,  2.6155e-01, -2.7933e-01,  1.3451e-01,\n",
       "         -1.4765e-01],\n",
       "        [ 1.1296e+00, -9.7838e-02,  8.1153e-01, -7.4696e-01,  2.3133e-01,\n",
       "         -6.4299e-01,  1.2702e+00, -1.9928e-01, -1.2474e+00,  4.2122e-01,\n",
       "          1.5488e+00, -1.2517e+00,  1.3148e+00, -2.2471e-01, -1.9381e+00,\n",
       "         -3.7858e-01],\n",
       "        [-6.4782e-01, -1.3268e+00, -8.8236e-01,  2.2093e-01,  6.7957e-01,\n",
       "          1.8177e+00, -1.0435e+00,  1.0793e+00, -3.1871e-02,  1.0966e+00,\n",
       "          2.5586e-01,  2.6705e-01, -1.9803e+00,  7.8523e-01, -8.7012e-01,\n",
       "          5.8046e-01],\n",
       "        [ 2.1015e-01, -1.8551e+00, -6.0552e-01, -7.4370e-01,  7.0660e-01,\n",
       "         -6.1453e-01, -5.0632e-01,  4.3819e-01,  9.2952e-01,  2.1337e+00,\n",
       "          4.3556e-01,  1.8818e-01, -1.0108e+00,  1.1879e+00, -1.3943e+00,\n",
       "          5.0046e-01],\n",
       "        [-1.1816e+00, -6.6000e-02,  7.8959e-01,  5.6693e-01, -2.2299e+00,\n",
       "          3.6017e-01, -2.6978e-01,  1.3283e+00, -6.8688e-02,  3.6036e-01,\n",
       "          2.2370e-02,  2.5713e-01,  1.3765e+00,  1.1813e+00, -8.3953e-01,\n",
       "         -1.5871e+00],\n",
       "        [ 6.7042e-01,  5.0248e-01,  1.5043e-03,  2.6312e-01, -9.1121e-01,\n",
       "          4.9817e-01, -7.9531e-01,  1.7955e+00, -2.1382e+00,  2.8231e-01,\n",
       "          7.9176e-01, -1.8184e+00,  1.0762e+00, -6.6889e-01,  2.0057e-01,\n",
       "          2.5007e-01],\n",
       "        [ 1.6131e+00,  5.6349e-01, -7.2674e-01, -1.3053e+00,  1.3998e+00,\n",
       "         -1.4846e+00, -3.0815e-01,  9.1062e-01,  8.1062e-02,  2.4119e-01,\n",
       "          8.7795e-02, -1.1950e+00, -1.6664e+00,  6.3750e-01,  1.2100e-01,\n",
       "          1.0307e+00],\n",
       "        [ 2.0297e+00, -1.7661e+00, -9.7165e-01, -1.1716e+00,  5.9662e-01,\n",
       "         -2.5900e-01, -1.5943e-01,  2.2132e+00, -2.3225e-01,  7.2753e-01,\n",
       "         -5.1924e-02, -2.9479e-01, -6.3435e-01,  1.1300e-01, -7.5032e-02,\n",
       "         -6.3965e-02],\n",
       "        [ 3.2417e-01, -4.0401e-01, -6.7396e-01, -1.3734e+00, -4.6658e-01,\n",
       "          6.2138e-01, -1.7022e-01,  2.0537e+00,  6.5040e-01,  3.9586e-01,\n",
       "         -4.1087e-02, -3.2520e-01, -2.2520e+00,  5.3787e-01, -4.0347e-01,\n",
       "          1.5265e+00],\n",
       "        [ 4.6230e-01, -2.0512e+00, -1.1297e+00, -1.0029e+00,  1.6912e-01,\n",
       "          3.5133e-01, -5.1807e-01,  7.4237e-01,  4.3642e-01,  2.4520e+00,\n",
       "         -4.3648e-01,  2.7984e-01, -2.9730e-01,  7.3975e-01, -8.7289e-01,\n",
       "          6.7546e-01],\n",
       "        [-1.2794e+00,  2.4661e-01, -1.7466e+00,  1.0403e-01,  6.2181e-01,\n",
       "          1.0829e+00, -4.1346e-01,  9.7816e-01, -6.8467e-01,  2.3659e+00,\n",
       "          5.7843e-01, -6.3881e-02, -1.4152e+00,  9.6819e-02, -3.4887e-01,\n",
       "         -1.2263e-01],\n",
       "        [ 2.8706e-01, -2.3959e-01, -4.1798e-01, -8.5304e-01, -9.5317e-01,\n",
       "          9.2663e-01, -1.2259e-01,  2.6404e+00,  7.4952e-01,  1.4556e+00,\n",
       "         -8.3763e-01, -8.2091e-02, -2.9476e-02, -8.5591e-01, -1.4215e+00,\n",
       "         -2.4631e-01],\n",
       "        [-1.1959e+00, -4.7860e-01, -2.0342e+00, -4.9381e-01, -1.1253e+00,\n",
       "         -4.6460e-01, -7.4933e-01,  2.0679e+00,  8.4265e-01,  5.3998e-01,\n",
       "          9.3318e-01,  4.8551e-01,  7.9733e-01,  8.4761e-01, -2.8318e-01,\n",
       "          3.1075e-01],\n",
       "        [-1.3108e-01, -4.8403e-01, -2.6949e+00, -2.6293e-01, -2.0326e-01,\n",
       "         -2.3190e-01, -1.6375e-01,  2.5512e+00, -7.6900e-02,  2.6798e-01,\n",
       "          3.8245e-01,  4.6773e-01, -6.7903e-01,  9.0551e-01,  1.8695e-01,\n",
       "          1.6587e-01],\n",
       "        [-1.2241e+00, -4.3095e-02, -3.1392e+00, -3.4995e-02,  2.3550e-01,\n",
       "          4.7236e-01,  1.8435e-01,  1.3301e+00,  5.0865e-01,  1.1054e+00,\n",
       "          1.7598e-01,  9.5749e-01, -1.7826e-01, -3.1365e-01,  1.8874e-02,\n",
       "         -5.5372e-02],\n",
       "        [-9.2493e-01, -1.0760e+00, -1.3546e+00,  4.9843e-01, -6.5246e-01,\n",
       "          2.3184e-01,  1.3264e+00,  2.2587e+00, -1.2326e+00,  9.3533e-01,\n",
       "          2.4326e-01,  8.1468e-01, -7.5483e-01,  6.0296e-01, -6.7313e-01,\n",
       "         -2.4308e-01]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_fwd = nn.Sequential(\n",
    "    nn.Linear(16, 16),\n",
    "    nn.Linear(16, 16),\n",
    "    nn.Linear(16, 16)\n",
    ")\n",
    "\n",
    "linear_out = feed_fwd(add_norm_layer1)\n",
    "\n",
    "out = layer_norm(add_norm_layer1+linear_out)\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if',\n",
       " 'you',\n",
       " 'miss',\n",
       " 'the',\n",
       " 'train',\n",
       " 'i',\n",
       " 'am',\n",
       " 'on',\n",
       " 'you',\n",
       " 'will',\n",
       " 'know',\n",
       " 'i',\n",
       " 'am',\n",
       " 'gone',\n",
       " 'you',\n",
       " 'will',\n",
       " 'hear',\n",
       " 'a',\n",
       " 'whistle',\n",
       " 'blow',\n",
       " 'a',\n",
       " 'hundred',\n",
       " 'miles']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_fwd2 = nn.Sequential(\n",
    "    nn.Linear(16, 16)\n",
    ")\n",
    "\n",
    "fin_out = feed_fwd2(out)\n",
    "\n",
    "probabilities = torch.softmax(fin_out[-1], dim=-1)\n",
    "\n",
    "#softmax = nn.Softmax(dim=-1)\n",
    "#fin_out_probs = softmax(fin_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n"
     ]
    }
   ],
   "source": [
    "next_word = words[probabilities.argmax()]\n",
    "print(next_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
